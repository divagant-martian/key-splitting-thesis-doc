% !TEX root = ../main.tex
\chapter{Preliminaries
  \label{chapter:preliminaries}}

  This section is a primer on stream processing. It covers the formalization of
  streams and related concepts, as well as the basics of the main
  characteristics that shape the general architecture of a Data Stream
  Processing System (DSPS). Subsequently, it provides an overview on the most
  common Quality of Service metrics, and how these are affected by
  architectural decisions, particularly regarding elasticity and distribution.
  It concludes with the definition of load balancing and the techniques used to
  handle this challenge, with a great emphasis on key splitting.

  \section{Data Stream Modeling}

  A stream is defined as an unbound sequence of tuples $\langle
  a_{\{i\}},\tau\rangle$. The $a_{\{i\}}$ are attributes of the tuple and may
  be of variable length or of fixed width in a structured data context. In the
  later, the $a_{\{i\}}$ would follow an schema $S$ which describe the expected
  data type and  content of each attribute. $\tau$ is the timestamp of each
  data point.

  \subsection{Operators}

  Streams are processed by functional units commonly known as operators or
  processing elements. Typical examples of operators include one-to-one
  mappings, filters and joins. Operator are classified as stateless or
  stateful.

  A stateless operator will process a tuple regardless of the previously seen
  items. Some examples are filters and simple one-to-one transformations,
  projections and constant functions. Stateless operators may produce a result
  taking into account values of an attribute. In the classic word-count example
  each item will produce the tuple $\langle seenword, 1\rangle$. The
  fundamental property of such operators is their lack of knowledge of the
  composition of previous tuples or their results.

  In contrast, a stateful operator will store the information of previous
  tuples, or the results it has produced for each item or the block itself. In
  the word-count example the second stage stores for each word the accumulated
  count and updates the result with each new seen occurrence. In this scenario,
  the stored information is an aggregated result. It is possible for the
  operator to need the items itself. For example, the calculation of a moving
  median of the last $n$ data points.

  \subsection{Directed Acyclic Graphs}
  The way data flows from one operator to another is defined in an abstract
  manner using a directed acyclic graph (DAG). The edges of the DAG represent
  the streams, and nodes represent both the operators which transform data and
  the sources and sinks as well. Sources are data producers such as sensors,
  IoT devices and social media, whose data is consumed by the system. Sinks are
  the final consumers of the process. The later are commonly web applications
  or storage systems.

  \insertfigure{styles/images/dag.eps}{Abstract workflow}{fig:dag}{\figwidth}

  Given the task of counting the amount of hashtags a user has used,
  \fref{fig:dag} is a possible DAG representing the work involved. $O1$ is the
  source that continuously feeds tweets into the system. $O3$ transforms the
  tweets removing the non-hashtag components of the tweet and generating
  ordered pairs of user and hashtag appearing together. $O5$ groups the
  resulting items in order to update the cumulated count. $O2$ and $O4$ might
  be part of an unrelated task (for instance, counting the tweets of only
  verified accounts). This is possible since a DAG may have several sinks.

  A DAG is an abstract view of the data flow and general workflow. However the
  actual implementation runs in a parallel, distributed system, where each
  operator can be replicated across physical machines to obtain better
  performance metrics.
  % DAG  \cite{kamburugamuve2013survey} % Operator Graphs \cite{R_ger_2019}
  % Workflow  \cite{KottoKombi2015ParallelAD}
  % General system model

  \subsection{Physical Plan}
  The introduction of distribution in stream processing allows operators to run
  on different physical nodes. Data parallelism gives the opportunity of
  processing more than one item simultaneously. Together they bring the concept
  of sub-stream processing. \Fref{fig:physical-plan} show how the DAG described
  by \fref{fig:dag} might be deployed in a parallel and distributed environment.

  \insertfigure{styles/images/physical-plan.eps}{Physical
  plan}{fig:physical-plan}{\figwidth}

  In this example, $O3$ is a stateless operator. Therefor, the transformation
  can be performed on every item regardless of the operator instance receiving
  it. In contrast, $O5$ is a stateful operator and works in a way that data
  needs to be repartitioned depending on which instance has the information of
  the item's key. Note that such difference has consequences on the patterns
  for data transportation between instances. Data from $O1$ to $O3$ travels on
  a one-to-one way, and a repartitioning one from $O3$ to $O5$

  The process through which \fref{fig:dag} becomes \fref{fig:physical-plan}
  includes a series of optimizations. It is possible to reorder, combine,
  divide and eliminate operators and still obtain the same desired results.
  \cite{Hirzel_2014} provides a comprehensive survey on these optimizations.

  \subsection{Parallelization in Stream Processing}

  Explicar que el paralelismo se puede evidenciar en dos modos a grandes
  rasgos: paralelismo de tareas o de datos. Explicar brevemente paralelismo de
  tareas y entrar en detalle en paralelismo de datos
  Explicar qué es elasticidad

  Decir que el paralelismo, en conjunto con la distribución ponen sobre la mesa
  características interesante de los sistemas de procesamientos de datos, o
  hacen que determinadas decisiones del modelo afecten sus capacidades de
  paralelismo. Explicar cuáles son estas caracterísicas: Type of SP System,
  Programming Model, Sub-Stream Processing, Modeo de insfraestructura, Manejo
  de estado en operadores. \cite{R_ger_2019} Decir por qué en cada
  clasificación se escogió el modelo que se escogió para trabajar bajo las
  garantías del sistema.


  Parallelization and Elasticity methods \cite{R_ger_2019}\\
  - Task parallelization \cite{R_ger_2019}\\
  - Shuffle grouping \cite{R_ger_2019}\\
  - Key partitioning functions \cite{R_ger_2019}\\
  - Key-based splitting: State Management and Algorithms \cite{R_ger_2019}\\
  - Operator Elasticity methods \cite{R_ger_2019}
  - Operator parallelization methods \cite{R_ger_2019}

  % Parallel Data Stream Processing Engines classification \cite{R_ger_2019}

  \section{QoS Metrics}
  QoS-Related Challenges\cite{chakravarthy2009stream}
  \section{Load Balancing in the context of elasticity and distribution}

  Problem description: Load Balancing  \cite{Hirzel_2014},   Load Balancing \cite{R_ger_2019}

  State management (considerations): State in Operators \cite{R_ger_2019}. State management \cite{R_ger_2019}: Safety and Profitability \cite{Schneider_2013}\cite{R_ger_2019}

  Other optimizations

  Comparison between most common engines taking into account all that was said in this section before
  Most common Engines  \cite{kamburugamuve2013survey}
  - Storm  \cite{kamburugamuve2013survey} \cite{R_ger_2019}\\
  - Heron \cite{R_ger_2019}\\
  - Spark \cite{R_ger_2019}\\
  - Flink \cite{R_ger_2019}

  Conclusion: Open Research Problems \cite{Schneider_2013}

